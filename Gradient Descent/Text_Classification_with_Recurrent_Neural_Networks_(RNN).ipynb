{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNLJx8IZvhqBZ/iddio91Cx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NDsasuke/Gradient-decent--simplex-method--Binary-linear-programming/blob/main/Gradient%20Descent/Text_Classification_with_Recurrent_Neural_Networks_(RNN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Preprocess Data:\n",
        "\n",
        "* The code loads the IMDB movie review dataset using imdb.load_data(). This dataset is a binary sentiment classification problem.\n",
        "* The data is split into training and testing sets: (x_train, y_train) contains the training data, and (x_test, y_test) contains the testing data.\n",
        "* The tf.keras.preprocessing.sequence.pad_sequences() function is used to preprocess the data by padding the sequences to a maximum length (max_len) to ensure uniformity."
      ],
      "metadata": {
        "id": "4kbbz4Sdrbko"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "2SFncnqDgXIp"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import imdb\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the IMDB movie review dataset (binary sentiment classification)\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n"
      ],
      "metadata": {
        "id": "dH3D6TwUrVt8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Preprocess the data\n",
        "max_len = 200  # Maximum sequence length\n",
        "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test, maxlen=max_len)"
      ],
      "metadata": {
        "id": "eYAlmLS6rQr1"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the RNN Model:\n",
        "\n",
        "* The RNN model is constructed using the Sequential() class from Keras.\n",
        "An embedding layer is added as the first layer, which maps the word indices to dense word embeddings of a specified dimension (embedding_dim).\n",
        "* An LSTM layer is added, which processes the embedded sequences and captures the context information.\n",
        "* Finally, a dense layer with a sigmoid activation function is added to produce a single output representing the sentiment prediction."
      ],
      "metadata": {
        "id": "9OvjAnGSrqRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the RNN model\n",
        "embedding_dim = 128  # Dimensionality of word embeddings\n",
        "model = Sequential()\n",
        "model.add(Embedding(10000, embedding_dim, input_length=max_len))\n",
        "model.add(LSTM(128))\n",
        "model.add(Dense(1, activation='sigmoid'))\n"
      ],
      "metadata": {
        "id": "wGA4rFmUrOu3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compile the Model:\n",
        "\n",
        "* The model is compiled using model.compile().\n",
        "* The loss function is set to 'binary_crossentropy' since it is a binary classification problem.\n",
        "* The optimizer used here is 'adam', which utilizes gradient descent methods for optimization.\n",
        "* The metric chosen is 'accuracy' to monitor the accuracy of the model during training.\n"
      ],
      "metadata": {
        "id": "R7FiJUYUry-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "GUG6mSmxrM3V"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Model:\n",
        "\n",
        "* The model is trained using model.fit().\n",
        "* The training data (x_train and y_train) are provided, along with the batch size and number of epochs.\n",
        "* During training, gradient descent is employed to update the model's * parameters iteratively, minimizing the loss and improving accuracy.\n",
        "* The validation data (x_test and y_test) are used to evaluate the model's performance on unseen data after each epoch.\n"
      ],
      "metadata": {
        "id": "nSXXDe_lr83n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(x_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PwOVZfJArMJP",
        "outputId": "d3f63b1c-ab08-461b-b3f5-b418e1389533"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "391/391 [==============================] - 47s 112ms/step - loss: 0.4505 - accuracy: 0.7856 - val_loss: 0.3590 - val_accuracy: 0.8493\n",
            "Epoch 2/5\n",
            "391/391 [==============================] - 17s 43ms/step - loss: 0.2608 - accuracy: 0.8987 - val_loss: 0.3335 - val_accuracy: 0.8607\n",
            "Epoch 3/5\n",
            "391/391 [==============================] - 13s 34ms/step - loss: 0.1885 - accuracy: 0.9281 - val_loss: 0.3388 - val_accuracy: 0.8636\n",
            "Epoch 4/5\n",
            "391/391 [==============================] - 10s 26ms/step - loss: 0.1389 - accuracy: 0.9503 - val_loss: 0.3614 - val_accuracy: 0.8494\n",
            "Epoch 5/5\n",
            "391/391 [==============================] - 10s 25ms/step - loss: 0.1142 - accuracy: 0.9601 - val_loss: 0.3921 - val_accuracy: 0.8480\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f9f8f5980d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the Model:\n",
        "\n",
        "* After training, the model's performance is evaluated using model.evaluate().\n",
        "The testing data (x_test and y_test) are provided to calculate the loss and accuracy of the model on unseen data.\n",
        "* The calculated loss and accuracy are printed to assess the model's performance."
      ],
      "metadata": {
        "id": "M26kNIjQsGeo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "loss, accuracy = model.evaluate(x_test, y_test)\n",
        "print(\"Test Loss:\", loss)\n",
        "print(\"Test Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuTTot6TrHns",
        "outputId": "42e495bf-3125-45f3-b601-2db8b6c9c1de"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 4s 6ms/step - loss: 0.3921 - accuracy: 0.8480\n",
            "Test Loss: 0.3920823931694031\n",
            "Test Accuracy: 0.8479999899864197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extract Word Index:\n",
        "\n",
        "* This segment extracts the word index from the IMDB dataset, which maps each word to a unique index.\n",
        "* The get_word_index() function from the IMDB dataset is used to retrieve the word index.\n",
        "* The extracted word index is then converted into a dictionary (index_to_word) for easy lookup, where the index is the key and the word is the value.\n",
        "* This segment also demonstrates how to convert a sample review from the dataset back into its original text form using the word index dictionary.\n",
        "* The sample review and its corresponding sentiment label are printed for inspection.\n"
      ],
      "metadata": {
        "id": "g7_oryYqsOIa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()\n",
        "index_to_word = {index: word for word, index in word_index.items()}\n",
        "\n",
        "# Print a sample review and its corresponding sentiment\n",
        "sample_review = ' '.join(index_to_word[index] for index in x_train[0])\n",
        "print(\"Sample Review:\", sample_review)\n",
        "print(\"Sentiment:\", y_train[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gF1bQtgVqRTL",
        "outputId": "d226157e-42c1-4afb-9ecf-28e0807189b5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Review: to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n",
            "Sentiment: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make Predictions:\n",
        "\n",
        "* This segment demonstrates how to use the trained RNN model to make predictions on new reviews.\n",
        "* It starts by providing a list of new reviews (new_reviews) as strings.\n",
        "Each review is tokenized into a sequence of words using text_to_word_sequence() from Keras.\n",
        "* The word sequences are then converted into sequences of word indices by mapping each word to its corresponding index from the word index dictionary.\n",
        "Padding is applied to ensure that all sequences have the same length as the training data.\n",
        "* The model's predict() function is used to obtain the predicted sentiment probabilities for each review.\n",
        "* A threshold of 0.5 is used to determine the sentiment label ('Positive' if the probability is above 0.5, 'Negative' otherwise).\n",
        "* The new reviews, along with their predicted sentiments, are printed for inspection."
      ],
      "metadata": {
        "id": "lw2gDrEOsaax"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions on new reviews\n",
        "new_reviews = ['This movie is fantastic!', 'I did not like the acting in this film.']\n",
        "sequences = [tf.keras.preprocessing.text.text_to_word_sequence(review) for review in new_reviews]\n",
        "sequences = [[word_index[word] for word in sequence if word in word_index] for sequence in sequences]\n",
        "sequences = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=max_len)\n",
        "\n",
        "predictions = model.predict(sequences)\n",
        "sentiments = ['Positive' if pred > 0.5 else 'Negative' for pred in predictions]\n",
        "\n",
        "for review, sentiment in zip(new_reviews, sentiments):\n",
        "    print(\"Review:\", review)\n",
        "    print(\"Sentiment:\", sentiment)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8wkfkIwpqh-T",
        "outputId": "778710bf-3aac-449f-b7ec-81a40a7fceab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 357ms/step\n",
            "Review: This movie is fantastic!\n",
            "Sentiment: Positive\n",
            "\n",
            "Review: I did not like the acting in this film.\n",
            "Sentiment: Positive\n",
            "\n"
          ]
        }
      ]
    }
  ]
}